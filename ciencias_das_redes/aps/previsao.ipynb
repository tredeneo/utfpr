{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício sobre pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o dataset 'datasetCarros.csv'.<br>\n",
    "Usando Pytorch, construa uma rede neural para prever a feature 'PrecoVenda'.<br>\n",
    "\n",
    "Use uma rede neural feed forward com duas camadas escondidas, com 20 neurônios cada.<br>\n",
    "Use o critério de perda MSELoss, otimizador Adam e learning rate = 0.001. Considere 1000 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# variavel binaria para decidir se vai tentar prever nota ou arrecadação\n",
    "NOTA = False\n",
    "\n",
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            \n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            output = self.fc1(x)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc2(output)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc3(output)\n",
    "\n",
    "            return output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "imdb = pd.read_csv('imdb_top_1000.csv')\n",
    "\n",
    "\n",
    "imdb = imdb.drop([\"Released_Year\",\"Poster_Link\",\"Overview\",\"No_of_Votes\",\"Meta_score\",\"Runtime\",\"Certificate\",\"Genre\",\"Director\"],axis=1)\n",
    "if NOTA:\n",
    "    imdb = imdb.drop([\"Gross\"],axis=1)\n",
    "else:\n",
    "    imdb= imdb.drop([\"IMDB_Rating\"],axis=1)\n",
    "    imdb = imdb[imdb['Gross'].notna()]\n",
    "    imdb = imdb.reset_index(drop=True)\n",
    "    imdb[\"Gross\"] = imdb[\"Gross\"].apply(lambda x:  int(str(x).replace(\",\",\"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformar atores para colunas categoricas, tirando a redundancia q teria com get_dummies: star1_Al_pacino, star2_Al_pacino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_total = []\n",
    "for _,linha in imdb.iterrows():\n",
    "    lista_total.append((linha[[\"Star1\",\"Star2\",\"Star3\",\"Star4\"]].values))\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "astros = pd.DataFrame(mlb.fit_transform(lista_total),columns=mlb.classes_)\n",
    "imdb = pd.concat([imdb,astros],axis=1)\n",
    "imdb = imdb.drop([\"Star1\",\"Star2\",\"Star3\",\"Star4\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NOTA:\n",
    "    y = imdb['IMDB_Rating']\n",
    "    X = imdb.drop([\"Series_Title\",'IMDB_Rating'],axis=1)\n",
    "else:\n",
    "    y = imdb['Gross']\n",
    "    X = imdb.drop([\"Series_Title\",'Gross'],axis=1)\n",
    "\n",
    "y_tensor = torch.tensor(y)\n",
    "X_tensor = torch.tensor(X.to_numpy())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_tensor, y_tensor, test_size = 0.10, random_state=5)\n",
    "\n",
    "\n",
    "X_treino = X_treino.float().to(device)\n",
    "y_treino = y_treino.float().to(device)\n",
    "\n",
    "\n",
    "X_teste = X_teste.float().to(device)\n",
    "y_teste = y_teste.float().to(device)\n",
    "\n",
    "X_tensor = torch.tensor(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnl/.local/share/virtualenvs/aps-BmxP0JNk/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([84])) that is different to the input size (torch.Size([84, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/dnl/.local/share/virtualenvs/aps-BmxP0JNk/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([747])) that is different to the input size (torch.Size([747, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste - perda antes do treinamento 1.8832332081332224e+16\n",
      "Epoch 0: perda treino: 1.6414947319742464e+16\n",
      "Epoch 500: perda treino: 1.6346451181305856e+16\n",
      "Epoch 1000: perda treino: 1.5888977034739712e+16\n",
      "Epoch 1500: perda treino: 1.4922105808224256e+16\n",
      "Epoch 2000: perda treino: 1.3672965036048384e+16\n",
      "Teste - perda depois do treinamento 1.6499103982682112e+16\n"
     ]
    }
   ],
   "source": [
    "model = Feedforward(X_tensor.shape[1], 20).to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "#criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_teste)\n",
    "antes_treino = criterion(y_pred, y_teste) \n",
    "print('Teste - perda antes do treinamento' , antes_treino.item())\n",
    "\n",
    "model.train()\n",
    "epoch = 2_500\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Passe Forward\n",
    "    y_pred = model(X_treino)\n",
    "    \n",
    "    # Computa a perda\n",
    "    loss = criterion(y_pred, y_treino)\n",
    "    if epoch % 500 == 0:\n",
    "        print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Passe de Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_teste)\n",
    "after_train = criterion(y_pred, y_teste) \n",
    "print('Teste - perda depois do treinamento' , after_train.item())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "atores = list(imdb.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegar_atores(nomes):\n",
    "    torch_tmp = torch.zeros(X_teste[0].shape)\n",
    "    indices = []\n",
    "    for i in nomes:\n",
    "        indices.append(atores.index(i))\n",
    "    for i in indices:\n",
    "        torch_tmp[i] = 1\n",
    "    return torch_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "batman_harry_potter = [\"Daniel Radcliffe\",\"Emma Watson\",\"Rupert Grint\",\"Christian Bale\",\"Michael Caine\"]\n",
    "harry_potter  = [\"Daniel Radcliffe\",\"Emma Watson\",\"Rupert Grint\"]\n",
    "poderoso_chefao = [\"Al Pacino\",\"Robert De Niro\"]\n",
    "\n",
    "aleatorio = random.sample(atores, 4)\n",
    "batman_harry_potter = pegar_atores(batman_harry_potter)\n",
    "aleatorio = pegar_atores(aleatorio)\n",
    "harry_potter = pegar_atores(harry_potter)\n",
    "poderoso_chefao = pegar_atores(poderoso_chefao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27194938.0\n",
      "18133548.0\n",
      "18129444.0\n",
      "9073548.0\n"
     ]
    }
   ],
   "source": [
    "print(model(batman_harry_potter).item())\n",
    "print(model(harry_potter).item())\n",
    "print(model(aleatorio).item())\n",
    "print(model(poderoso_chefao).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
